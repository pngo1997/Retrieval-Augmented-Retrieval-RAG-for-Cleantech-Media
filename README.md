# ğŸ” Retrieval Augmented Generation (RAG) for Cleantech Media  

## ğŸ“œ Overview  
This project focuses on implementing a **Retrieval-Augmented Generation (RAG) system** to retrieve and summarize clean technology articles. Using the **Cleantech Media Dataset** from Kaggle, the system processes, stores, and retrieves articles using vector databases and generates responses via **Large Language Models (LLMs)**.  

The project builds upon the **"Cleantech RAG"** tutorial from the **Next-Gen Cleantech Solutions workshop** (SwissText2024). It incorporates **additional enhancements**, including alternative text splitters, embeddings, LLMs, and evaluation techniques.  

## ğŸš€ 1ï¸âƒ£ System Workflow  

1ï¸âƒ£ **Vector Database Creation**  
- Preprocess **20,122 articles** from the **Cleantech Media Dataset**.  
- Chunk articles using multiple **text splitters** (RecursiveCharacter, NLTKTextSplitter).  
- Store chunks in a **vector database** using embeddings.  

2ï¸âƒ£ **Query Processing via RAG Pipeline**  
- User submits a **clean technology-related query**.  
- Retrieve relevant chunks from the **vector database**.  
- Generate an **answer summary** using an **LLM**.  

3ï¸âƒ£ **Evaluation & Benchmarking**  
- Evaluate retrieval performance using **Cleantech RAG Evaluation Dataset (23 instances)**.  
- Compare different retrieval settings, LLM models, and prompt variations.  
- Use **ROUGE, Perplexity, BERTScore, and RAGAS metrics** for evaluation.  
- Conduct **qualitative analysis** of generated responses.  

## ğŸ“Š 2ï¸âƒ£ Dataset  

### **1. Training Dataset**  
ğŸ“„ **Cleantech Media Dataset** ([Kaggle](https://www.kaggle.com/datasets/anacode/cleantech-media-dataset))  
- **20,122 web articles** on clean technologies.  
- Sources: **pv-magazine, energy-xprt, and more**.  
- Timeframe: **Jan 2022 â€“ Oct 2024**.  
- Used to **build the retrieval system**.  

### **2. Evaluation Dataset**  
ğŸ“„ **Cleantech RAG Evaluation Dataset**  
- **23 evaluation instances** for RAG performance testing.  
- Used for **retrieval and answer generation assessment**.  

ğŸ“Œ **Parsing Note**:  
- Uses **`;` delimiter** instead of `,` (important for correct parsing).  
- **Columns Used**:  
  - `question` â†’ **User query**  
  - `relevant_text` â†’ **Ground truth for retrieval**  
  - `answer` â†’ **Expected generated response**  

## ğŸ›  3ï¸âƒ£ Implementation Details  

### **ğŸ“Œ 1. Data Processing & Chunking**  
âœ… **Text Splitters Used**:  
- **RecursiveCharacterTextSplitter** (baseline)  
- **NLTKTextSplitter** (linguistically aware)  

ğŸ“Œ **Chunk Configurations**:  
- **(256, 64)**  
- **(1024, 128)**  

âœ… **Enhancements**:  
- Added **"in-document chunk ID"** to metadata.  
- Preprocessed text to improve chunk separation.
  
### **ğŸ“Œ 2. Embeddings & Vector Database**  
âœ… **Embedding Models Used**:  
1ï¸âƒ£ **"mini"**  
2ï¸âƒ£ **"bge-m3"**  
3ï¸âƒ£ **"gte"**  

âœ… **Analysis Performed**:  
- **Embedding space distribution**  
- **Similarity statistics**  

### **ğŸ“Œ 3. RAG Pipeline Enhancements**  

âœ… **New Components Added**:  
- **Alternative RAG prompts** for better chunk retrieval.  
- **Different values for retrieved chunks (k = {1, 3, 5})**.  

âœ… **LLMs Used**:  
- **GPT-4-turbo**  

âœ… **Evaluation Experiments**:  
- Impact of chunk retrieval count (`k`) on results.  
- Performance comparison of different LLMs.  

### **ğŸ“Œ 4. Answer Generation & Evaluation**  

âœ… **Additional Prompt Experiments**:  
- Designed alternative `answer_generation_prompt` for better summaries.  

âœ… **Metrics Used for Evaluation**:  
1ï¸âƒ£ **ROUGE** (Lexical overlap)  
2ï¸âƒ£ **Perplexity** (Fluency measurement)  
3ï¸âƒ£ **BERTScore** (Semantic similarity)  
4ï¸âƒ£ **RAGAS** (RAG-specific retrieval evaluation)  

âœ… **Qualitative Analysis**:  
- **Manual review of select query responses**.  
- **Comparison between LLM-generated and ground-truth answers**.  

ğŸ“Œ **Optional Enhancements**:  
- **Synthetic Q-A pair generation** (`generate_synthetic_qa_pairs()`).  
- **Advanced RAG techniques**.  

## ğŸ“Œ 5ï¸âƒ£ Summary  

âœ… Implemented RAG pipeline on Cleantech dataset.

âœ… Enhanced retrieval using new chunking methods.

âœ… Analyzed embedding models & retrieval effectiveness.

âœ… Experimented with multiple LLMs & prompt designs.

âœ… Evaluated system with ROUGE, Perplexity, BERTScore & RAGA.

âœ… Performed qualitative analysis on generated responses.
